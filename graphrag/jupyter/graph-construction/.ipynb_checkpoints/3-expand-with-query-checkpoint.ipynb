{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Expand Context\n",
    "\n",
    "The Chunk Nodes are individual chunks of text that used\n",
    "to be part of an entire document.\n",
    "\n",
    "You can reconstruct the original context by connecting the nodes\n",
    "with relationships. It also makes the data easy to navigate and understand.\n",
    "\n",
    "That is super helpful when you're building an application, for debugging and testing.\n",
    "\n",
    "And, you can provide a better user experience. Your users will be able \n",
    "to directly interact with the data and even provide feedback that will\n",
    "improve subsequent answers. \n",
    "\n",
    "You will create a connected context by making the following\n",
    "changes to the knowledge graph:\n",
    "\n",
    "1. Extract, create `(:Document)` nodes for each original source Form.\n",
    "2. Enhance, add a summarized text property to each `(:Form)` node.\n",
    "3. Expand, connect each `(:Chunk)` to the `(:Form)` node that it is part of\n",
    "\n",
    "The graph will look like this...\n",
    "\n",
    "```cypher\n",
    "(:Document\n",
    "  docId: string\n",
    "  uri: string\n",
    "  summary: text\n",
    "  summaryEmbedding: float[] // vector embedding of summary\n",
    ")\n",
    "\n",
    "(:Section \n",
    "  sectionId: string //  a unique identifier for the form\n",
    "  summary: string // text summary generated with the LLM \n",
    "  summaryEmbedding: float[] // vector embedding of summary\n",
    ")\n",
    "```\n",
    "\n",
    "```cypher\n",
    "// Document contains sections\n",
    "(:Document)-[:CONTAINS]->(:Section)\n",
    "\n",
    "// Section contains Chunks\n",
    "(:Section)-[:CONTAINS]->(:Chunk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "Connecting to Neo4j at bolt://neo4j-1:7687 as neo4j\n",
      "Using data from /home/jovyan/data/single\n",
      "Embedding with ollama using mxbai-embed-large\n",
      "Chatting with ollama using llama3\n"
     ]
    }
   ],
   "source": [
    "%run 'shared.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Section Nodes\n",
    "\n",
    "There will be one Document node for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parent sections from Chunk nodes\n",
    "\n",
    "cypher_create_from_chunks = \"\"\"\n",
    "            MATCH (c:Chunk)\n",
    "            WITH c, apoc.util.sha1([coalesce(c.header4, c.header3, c.header2, c.header1)]) AS sectionId\n",
    "            MERGE (s:Section {sectionId: sectionId } )\n",
    "            SET s.header1 = c.header1\n",
    "            , s.header2 = c.header2\n",
    "            , s.header3 = c.header3\n",
    "            , s.documentUri = c.documentUri\n",
    "            , s.level = CASE WHEN c.header4 IS NOT NULL THEN 4\n",
    "                             WHEN c.header3 IS NOT NULL THEN 3\n",
    "                             WHEN c.header2 IS NOT NULL THEN 2\n",
    "                             WHEN c.header1 IS NOT NULL THEN 1\n",
    "                        END \n",
    "            , s.text = coalesce(c.header4, c.header3, c.header2, c.header1)   \n",
    "            MERGE (s)-[newRel:CONTAINS]->(c)\n",
    "            \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0xffff33d63a50>, keys=[])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdb.execute_query(cypher_create_from_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all other sections based on the parent nodes created before\n",
    "\n",
    "cypher_create_other_sections = \"\"\"\n",
    "            MATCH (e:Section)\n",
    "            WHERE e.level = $level_to_create+1\n",
    "            WITH e, CASE WHEN $level_to_create = 1 THEN e.header1\n",
    "                    WHEN $level_to_create = 2 THEN e.header2\n",
    "                    WHEN $level_to_create = 3 THEN e.header3\n",
    "                    END as text\n",
    "            WITH e, text, apoc.util.sha1([ text ]) AS sectionId    \n",
    "            MERGE (s:Section {sectionId: sectionId} )\n",
    "            set s.header1 = e.header1\n",
    "                , s.header2 = e.header2\n",
    "                , s.documentUri = e.documentUri\n",
    "                , s.level = $level_to_create\n",
    "                , s.text = text    \n",
    "            MERGE (s)-[newRel:CONTAINS]->(e)\n",
    "            \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0xffff33dd6f90>, keys=[])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdb.execute_query(cypher_create_other_sections, level_to_create=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0xffff33fe4390>, keys=[])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdb.execute_query(cypher_create_other_sections, level_to_create=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0xffff33d62ed0>, keys=[])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdb.execute_query(cypher_create_other_sections, level_to_create=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0xffff33dd9610>, keys=[])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a uniqueness constraint on the textId property of Text nodes \n",
    "gdb.execute_query('CREATE CONSTRAINT unique_section IF NOT EXISTS FOR (n:Section) REQUIRE n.sectionId IS UNIQUE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1942152747.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[107], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    MATCH (c:Chunk)-[r:NEXT]->(c1:Chunk) DELETE r\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "MATCH (c:Chunk)-[r:NEXT]->(c1:Chunk) DELETE r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Document nodes\n",
    "\n",
    "You can now create a Document node for each of the distinct documentUri's of the level 1 nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0xffff33bce510>, keys=[])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create all other sections based on the parent nodes created before\n",
    "\n",
    "cypher_create_documents = \"\"\"\n",
    "            MATCH (s:Section)\n",
    "            WHERE s.level = 1\n",
    "            MERGE (d:Document {documentId: apoc.util.sha1([s.documentUri]) } )\n",
    "            SET d.documentUri = s.documentUri\n",
    "            MERGE (d)-[newRel:CONTAINS]->(s)\n",
    "            \"\"\"\n",
    "\n",
    "gdb.execute_query(cypher_create_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance - create summary property, with embedding\n",
    "\n",
    "During the file processing above, the text from all interesting\n",
    "items were added to the `fullText` property of the `all_forms` dictionaries.\n",
    "\n",
    "We'll use an LLM to summarize the text and create an embedding.\n",
    "\n",
    "Both the text summary and the embdding will be added to the Section nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings will have 1024 dimensions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Record id=12 name='chunks_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Chunk'] properties=['embedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 17, 54, 57, 672000000, tzinfo=<UTC>) readCount=2>,\n",
       " <Record id=6 name='sections_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Section'] properties=['summaryEmbedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 17, 46, 42, 478000000, tzinfo=<UTC>) readCount=1>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an embedding to find out the dimensions of the vector\n",
    "text_embedding = embeddings_api.embed_query(\"embed this text using an LLM\")\n",
    "vector_dimensions = len(text_embedding) \n",
    "\n",
    "print(f\"Text embeddings will have {vector_dimensions} dimensions\")\n",
    "# Create a vector index called \"sections_vector\" the `summaryEmbedding`` property of nodes labeled `Section`. \n",
    "gdb.execute_query(\"\"\"\n",
    "         CREATE VECTOR INDEX `sections_vector` IF NOT EXISTS\n",
    "          FOR (s:Section) ON (s.summaryEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: $vectorDimensionsParam,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\",\n",
    "  vectorDimensionsParam=vector_dimensions\n",
    ")\n",
    "\n",
    "# Check the vector indexes in the graph\n",
    "gdb.execute_query('SHOW VECTOR INDEXES').records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (s:Section)-[:CONTAINS]->(c:Chunk)\n",
    "WITH s, collect(c.text) as textList\n",
    "RETURN s.sectionId AS sectionId, s.level AS level, apoc.text.join(textList, \" \\n \") AS text\n",
    "\"\"\"\n",
    "\n",
    "sections_with_text = gdb.execute_query(query).records\n",
    "for section in sections_with_text[0:]:\n",
    "    section_info = {}\n",
    "    text = section[\"text\"]\n",
    "    result = chat_api.invoke(\n",
    "      f\"\"\"Write a single, very brief sentence summary\n",
    "       based on the following information...\\n {text}. Do not respond with \"Here is a brief sentence summary:\" \n",
    "      \"\"\")\n",
    "    summary = result.content\n",
    "    print(f\"Summarized {len(summary)} characters. Here's a preview...\")\n",
    "    print(f\"\\t{summary[:120]}\")\n",
    "    section_info['summary'] = summary\n",
    "    section_info['sectionId'] = section[\"sectionId\"]\n",
    "    \n",
    "    summary_embedding = embeddings_api.embed_query(summary)\n",
    "    section_info['summaryEmbedding'] = summary_embedding\n",
    "    print(f\"\\tUpdating section with ID {section_info['sectionId']} with summary and embedding...\")\n",
    "    gdb.execute_query(\"\"\"\n",
    "      MATCH (s:Section {sectionId: $sectionInfoParam.sectionId})\n",
    "        SET s.summary = $sectionInfoParam.summary \n",
    "      WITH s\n",
    "        CALL db.create.setNodeVectorProperty(s, \"summaryEmbedding\", $sectionInfoParam.summaryEmbedding)    \n",
    "    \"\"\", \n",
    "    sectionInfoParam=section_info\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vector index: sections_vector\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m search_results \u001b[38;5;241m=\u001b[39m neo4j_vector_search(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhat is the size of the rink?\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msections_vector\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m \u001b[43msearch_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "search_results = neo4j_vector_search(\n",
    "    'what is the size of the rink?', 'sections_vector'\n",
    ")\n",
    "search_results[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance - create hypotetical question nodes, with embedding\n",
    "\n",
    "During the file processing above, the text from all interesting\n",
    "items were added to the `fullText` property of the `all_forms` dictionaries.\n",
    "\n",
    "We'll use an LLM to generate the questions and create an embedding.\n",
    "\n",
    "Both the text summary and the embdding will be added to the Form nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the total area of the Goalkeeper Restricted Area?', 'How many meters longer is one side of the trapezoid compared to the other?', \"If a player's skate extends 0.1m beyond the red line, will it be considered out of bounds?\"]\n"
     ]
    }
   ],
   "source": [
    "text = \"The Goalkeeper Restricted Area is a trapezoidal zone marked behind each goal on the ice surface, defined by two red lines that measure 6.80m along the goal line and 8.60m along the boards\"\n",
    "result = chat_api.invoke(\n",
    "      f\"\"\"Generate a maximum of 3 short hypothetical questions based on the information from the text\\n {text}. Only respond with the questions delimited by a newline (\\n) and do not return \"Here are some hypothetical questions based on the information:\" \n",
    "      \"\"\")\n",
    "print (result.content.split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings will have 1024 dimensions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Record id=12 name='chunks_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Chunk'] properties=['embedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 18, 0, 56, 401000000, tzinfo=<UTC>) readCount=5>,\n",
       " <Record id=2 name='questions_vector' state='POPULATING' populationPercent=0.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Question'] properties=['embedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=None readCount=None>,\n",
       " <Record id=6 name='sections_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Section'] properties=['summaryEmbedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 17, 46, 42, 478000000, tzinfo=<UTC>) readCount=1>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an embedding to find out the dimensions of the vector\n",
    "text_embedding = embeddings_api.embed_query(\"embed this text using an LLM\")\n",
    "vector_dimensions = len(text_embedding) \n",
    "\n",
    "print(f\"Text embeddings will have {vector_dimensions} dimensions\")\n",
    "# Create a vector index called \"sections_vector\" the `summaryEmbedding`` property of nodes labeled `Section`. \n",
    "gdb.execute_query(\"\"\"\n",
    "         CREATE VECTOR INDEX `questions_vector` IF NOT EXISTS\n",
    "          FOR (s:Question) ON (s.embedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: $vectorDimensionsParam,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\",\n",
    "  vectorDimensionsParam=vector_dimensions\n",
    ")\n",
    "\n",
    "# Check the vector indexes in the graph\n",
    "gdb.execute_query('SHOW VECTOR INDEXES').records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Inserting Question node with question and embedding link it to Section with ID ca4f9dcf204e2037bfe5884867bead98bd9cbaf8 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID ca4f9dcf204e2037bfe5884867bead98bd9cbaf8 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID ca4f9dcf204e2037bfe5884867bead98bd9cbaf8 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID 70669d65799f0b85f53fa4d87f745b1ec129af58 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID 70669d65799f0b85f53fa4d87f745b1ec129af58 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID 70669d65799f0b85f53fa4d87f745b1ec129af58 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID 3256ff621b0e47207f42b2db33a4589ec1ddd458 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID 3256ff621b0e47207f42b2db33a4589ec1ddd458 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID 3256ff621b0e47207f42b2db33a4589ec1ddd458 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID b9ea9b87e07555afd018b9a39b5c3e4180414475 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID b9ea9b87e07555afd018b9a39b5c3e4180414475 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID b9ea9b87e07555afd018b9a39b5c3e4180414475 ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID c31a58e8aebfd957ed100bf860f367a0ca7c37de ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID c31a58e8aebfd957ed100bf860f367a0ca7c37de ...\n",
      "\\Inserting Question node with question and embedding link it to Section with ID c31a58e8aebfd957ed100bf860f367a0ca7c37de ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import uuid\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (s:Section)-[:CONTAINS]->(c:Chunk)\n",
    "WITH s, collect(c.text) as textList\n",
    "RETURN s.sectionId AS sectionId, s.level AS level, apoc.text.join(textList, \" \\n \") AS text\n",
    "\"\"\"\n",
    "\n",
    "sections_with_text = gdb.execute_query(query).records\n",
    "for section in sections_with_text[0:]:\n",
    "    question_info = {}\n",
    "    text = section[\"text\"]\n",
    "    result = chat_api.invoke(f\"\"\"\n",
    "                Generate a maximum of 3 short hypothetical questions based on the information from the text\\n {text}. Only respond with the questions delimited by a newline (\\n) and do not return \"Here are some hypothetical questions based on the information:\n",
    "                \"\"\" \n",
    "    )    \n",
    "    questions = result.content.split('\\n\\n')\n",
    "    for question in questions:\n",
    "        question_info['question'] = question\n",
    "        question_info['sectionId'] = section[\"sectionId\"]\n",
    "        question_info['questionId'] = str(uuid.uuid4())\n",
    "    \n",
    "        question_embedding = embeddings_api.embed_query(question)\n",
    "        question_info['embedding'] = question_embedding\n",
    "        print(f\"\\Inserting Question node with question and embedding link it to Section with ID {question_info['sectionId']} ...\")\n",
    "\n",
    "        gdb.execute_query(\"\"\"\n",
    "          MERGE (q:Question {questionId: $questionInfoParam.questionId} )\n",
    "            SET q.question = $questionInfoParam.question \n",
    "          WITH q\n",
    "            CALL db.create.setNodeVectorProperty(q, \"embedding\", $questionInfoParam.embedding)\n",
    "          MATCH (s:Section {sectionId: $questionInfoParam.sectionId} )\n",
    "          MERGE (s)-[r:HAS_QUESTION]->(q)\n",
    "        \"\"\", \n",
    "        questionInfoParam=question_info\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c751aae4-dfff-4f5f-ab8a-ddea14154037\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "uuid4 = uuid.uuid4()\n",
    "print(str(uuid4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
