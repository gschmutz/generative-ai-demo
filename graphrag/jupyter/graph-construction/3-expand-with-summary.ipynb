{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Expand With Summary\n",
    "\n",
    "The Chunk Nodes are individual chunks of text that used\n",
    "to be part of an entire document.\n",
    "\n",
    "You can reconstruct the original context by connecting the nodes\n",
    "with relationships. It also makes the data easy to navigate and understand.\n",
    "\n",
    "That is super helpful when you're building an application, for debugging and testing.\n",
    "\n",
    "And, you can provide a better user experience. Your users will be able \n",
    "to directly interact with the data and even provide feedback that will\n",
    "improve subsequent answers. \n",
    "\n",
    "You will create a connected context by making the following\n",
    "changes to the knowledge graph:\n",
    "\n",
    "1. Extract, create `(:Document)` nodes for each original source Form.\n",
    "2. Enhance, add a summarized text property to each `(:Form)` node.\n",
    "3. Expand, connect each `(:Chunk)` to the `(:Form)` node that it is part of\n",
    "\n",
    "The graph will look like this...\n",
    "\n",
    "```cypher\n",
    "(:Section \n",
    "  sectionId: string //  a unique identifier for the form\n",
    "  documentUri: string\n",
    "  summary: string // text summary generated with the LLM \n",
    "  summaryEmbedding: float[] // vector embedding of summary\n",
    ")\n",
    "```\n",
    "\n",
    "```cypher\n",
    "// Document contains sections\n",
    "(:Document)-[:CONTAINS]->(:Section)\n",
    "\n",
    "// Section contains Chunks\n",
    "(:Section)-[:CONTAINS]->(:Chunk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "Connecting to Neo4j at bolt://neo4j-1:7687 as neo4j\n",
      "Using data from /home/jovyan/data/single\n",
      "Embedding with ollama using mxbai-embed-large\n",
      "Chatting with ollama using llama3\n"
     ]
    }
   ],
   "source": [
    "%run 'shared.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance - create summary property, with embedding\n",
    "\n",
    "During the file processing above, the text from all interesting\n",
    "items were added to the `fullText` property of the `all_forms` dictionaries.\n",
    "\n",
    "We'll use an LLM to summarize the text and create an embedding.\n",
    "\n",
    "Both the text summary and the embdding will be added to the Section nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings will have 1024 dimensions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Record id=12 name='chunks_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Chunk'] properties=['embedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 17, 54, 57, 672000000, tzinfo=<UTC>) readCount=2>,\n",
       " <Record id=6 name='sections_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Section'] properties=['summaryEmbedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 17, 46, 42, 478000000, tzinfo=<UTC>) readCount=1>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an embedding to find out the dimensions of the vector\n",
    "text_embedding = embeddings_api.embed_query(\"embed this text using an LLM\")\n",
    "vector_dimensions = len(text_embedding) \n",
    "\n",
    "print(f\"Text embeddings will have {vector_dimensions} dimensions\")\n",
    "# Create a vector index called \"sections_vector\" the `summaryEmbedding`` property of nodes labeled `Section`. \n",
    "gdb.execute_query(\"\"\"\n",
    "         CREATE VECTOR INDEX `sections_vector` IF NOT EXISTS\n",
    "          FOR (s:Section) ON (s.summaryEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: $vectorDimensionsParam,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\",\n",
    "  vectorDimensionsParam=vector_dimensions\n",
    ")\n",
    "\n",
    "# Check the vector indexes in the graph\n",
    "gdb.execute_query('SHOW VECTOR INDEXES').records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (s:Section)-[:CONTAINS]->(c:Chunk)\n",
    "WITH s, collect(c.text) as textList\n",
    "RETURN s.sectionId AS sectionId, s.level AS level, apoc.text.join(textList, \" \\n \") AS text\n",
    "\"\"\"\n",
    "\n",
    "sections_with_text = gdb.execute_query(query).records\n",
    "for section in sections_with_text[0:]:\n",
    "    section_info = {}\n",
    "    text = section[\"text\"]\n",
    "    result = chat_api.invoke(\n",
    "      f\"\"\"Write a single, very brief sentence summary\n",
    "       based on the following information...\\n {text}. Do not respond with \"Here is a brief sentence summary:\" \n",
    "      \"\"\")\n",
    "    summary = result.content\n",
    "    print(f\"Summarized {len(summary)} characters. Here's a preview...\")\n",
    "    print(f\"\\t{summary[:120]}\")\n",
    "    section_info['summary'] = summary\n",
    "    section_info['sectionId'] = section[\"sectionId\"]\n",
    "    \n",
    "    summary_embedding = embeddings_api.embed_query(summary)\n",
    "    section_info['summaryEmbedding'] = summary_embedding\n",
    "    print(f\"\\tUpdating section with ID {section_info['sectionId']} with summary and embedding...\")\n",
    "    gdb.execute_query(\"\"\"\n",
    "      MATCH (s:Section {sectionId: $sectionInfoParam.sectionId})\n",
    "        SET s.summary = $sectionInfoParam.summary \n",
    "      WITH s\n",
    "        CALL db.create.setNodeVectorProperty(s, \"summaryEmbedding\", $sectionInfoParam.summaryEmbedding)    \n",
    "    \"\"\", \n",
    "    sectionInfoParam=section_info\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (c:Chunk)<-[:CONTAINS]-(s:Section)\n",
    "WHERE c.header4 = '8.1. INJURED PLAYER'\n",
    "    RETURN c, s\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
