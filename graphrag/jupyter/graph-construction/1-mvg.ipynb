{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Minimum Viable Graph (MVG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you'll create the Minimumm Viable Graph consisting of `Chunk` nodes arranged into linked lists.\n",
    "\n",
    "\n",
    "1. Extract text from Form10k files, split into chunks, create `Chunk` nodes\n",
    "2. Enhance each `Chunk` node with a text embedding\n",
    "3. Expand the `Chunk` nodes with `NEXT` relationships to form linked lists\n",
    "\n",
    "```cypher\n",
    "(:Chunk \n",
    "  chunkId: string\n",
    "  source: string\n",
    "  text: string\n",
    "  header1: string\n",
    "  header2: string\n",
    "  header3: string\n",
    "  header4: string\n",
    "  path: string\n",
    "  documentUri: string\n",
    "  ebmbedding: float[]\n",
    ")\n",
    "```\n",
    "\n",
    "```cypher\n",
    "(:Chunk)-[:NEXT]->(:Chunk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import some python packages, set up global constants, and create a connection to the Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n",
      "Connecting to Neo4j at bolt://neo4j-1:7687 as neo4j\n",
      "Using data from /home/jovyan/data/single\n",
      "Embedding with ollama using mxbai-embed-large\n",
      "Chatting with ollama using llama3\n"
     ]
    }
   ],
   "source": [
    "%run 'shared.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a GraphDatabase interface\n",
    "\n",
    "You will use the Neo4j `GraphDatabase` interface to send queries to the Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, World!'"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect `gdb` to be defined in the shared notebook\n",
    "# gdb = GraphDatabase.driver(uri=NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "result = gdb.execute_query(\"RETURN 'Hello, World!' AS message\")\n",
    "\n",
    "result.records[0].get('message')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data pre-preprocessing\n",
    "\n",
    "The IIHF data you will be working with has been preprocessed from the original source. \n",
    "\n",
    "Please see the [Form10k Preprocessing](https://github.com/neo4j-product-examples/data-prep-sec-edgar/) repository for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step inspection of a single form 10k document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with one file\n",
    "\n",
    "Get the the file name and then loading the json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data-transfer/iihf/rulebook.md\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('/data-transfer/iihf', glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "print (documents[0].metadata[\"source\"])\n",
    "print (len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text splitter from Langchain\n",
    "\n",
    "You can use a text splitter function from Langchain.\n",
    "\n",
    "The `RecursiveCharacterTextSplitter` will use newlines\n",
    "and then whitespace characters to break down a text until\n",
    "the chunks are small enough. This strategy is generally\n",
    "good at keeping paragraphs together.\n",
    "\n",
    "Set a chunk size of 2000 characters,\n",
    "with 200 characters of overlap between each chunk,\n",
    "using the built-in `len` function to calculate the \n",
    "text length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting text into chunks using the RecursiveCharacterTextSplitter \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text splitter demonstration\n",
    "\n",
    "You can see what the text splitter will do by splitting up\n",
    "the `item1_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# IIHF Official Rulebook 2023/24\\n\\n## Welcome\\n\\nNo matter where ice hockey is played, the object of the game is the same – to put the puck into the opponent’s goal. Beyond that, ice hockey across the globe is subject to certain variations. This makes the rules of the game extremely important. These rules must be followed all times, in all countries, in all age categories, for the game to be enjoyed by everyone.\\n\\nHockey’s speed is one of the qualities that makes it so exciting. But this skill and excitement must be balanced with fair play and respect.\\n\\nIt is, therefore, important to make a clear separation between the purpose of all the elements of the game and to use these respectfully. These distinctions can be taught at an early age or whenever one begins to show interest in the game. And this is why hockey development begins with parents and coaches, those people most influential in guiding a person, old or young, into playing the game properly and within the rules.\\n\\nThe IIHF Championship program encompasses 81 Member National Associations, five age and gender categories over 30 international ice hockey tournaments, including the Olympic Winter Games.\\n\\nThe extensiveness of the program is acknowledged in the rule book. The goal is to provide everyone one set of rules from which to work. This presents a fair and leveled standard of play. It is a means of keeping the game’s “language” the same regardless of where it is played.\\n\\n## SECTION 01 PLAYING AREA\\n\\n### RULE 1 RINK\\n\\n#### 1.1 RINK\\n\\nGames under jurisdiction of the IIHF shall be played on an ice surface known as the “Rink” and must adhere to the dimensions and specifications prescribed by the IIHF and these rules.\\n\\nNo ice markings shall be permitted except those provided for under these rules unless express written permission has been obtained from the IIHF. On-ice logos must not interfere with any official ice markings provided for the proper playing of the game.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item1_text_chunks = text_splitter.split_text(documents[0].page_content)\n",
    "item1_text_chunks[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Header Text Splitter from Langchain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data-transfer/iihf/rulebook.md\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print (documents[0].metadata[\"source\"])\n",
    "print (len(documents))\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"header1\"),\n",
    "    (\"##\", \"header2\"),\n",
    "    (\"###\", \"header3\"),\n",
    "    (\"####\", \"header4\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=True)\n",
    "md_header_splits = markdown_splitter.split_text(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='No matter where ice hockey is played, the object of the game is the same – to put the puck into the opponent’s goal. Beyond that, ice hockey across the globe is subject to certain variations. This makes the rules of the game extremely important. These rules must be followed all times, in all countries, in all age categories, for the game to be enjoyed by everyone.  \\nHockey’s speed is one of the qualities that makes it so exciting. But this skill and excitement must be balanced with fair play and respect.  \\nIt is, therefore, important to make a clear separation between the purpose of all the elements of the game and to use these respectfully. These distinctions can be taught at an early age or whenever one begins to show interest in the game. And this is why hockey development begins with parents and coaches, those people most influential in guiding a person, old or young, into playing the game properly and within the rules.  \\nThe IIHF Championship program encompasses 81 Member National Associations, five age and gender categories over 30 international ice hockey tournaments, including the Olympic Winter Games.  \\nThe extensiveness of the program is acknowledged in the rule book. The goal is to provide everyone one set of rules from which to work. This presents a fair and leveled standard of play. It is a means of keeping the game’s “language” the same regardless of where it is played.', metadata={'header1': 'IIHF Official Rulebook 2023/24', 'header2': 'Welcome'})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Character Text Splitter from Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='No matter where ice hockey is played, the object of the game is the same – to put the puck into the opponent’s goal. Beyond that, ice hockey across the globe is subject to certain variations. This makes the rules of the game extremely important. These rules must be followed all times, in all countries, in all age categories, for the game to be enjoyed by everyone.  \\nHockey’s speed is one of the qualities that makes it so exciting. But this skill and excitement must be balanced with fair play and respect.', metadata={'header1': 'IIHF Official Rulebook 2023/24', 'header2': 'Welcome'})"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Char-level splits\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 600\n",
    "chunk_overlap = 0\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,    \n",
    ")\n",
    "\n",
    "# Split\n",
    "chunks = text_splitter.split_documents(md_header_splits)\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='No matter where ice hockey is played, the object of the game is the same – to put the puck into the opponent’s goal. Beyond that, ice hockey across the globe is subject to certain variations. This makes the rules of the game extremely important. These rules must be followed all times, in all countries, in all age categories, for the game to be enjoyed by everyone.', metadata={'header1': 'IIHF Official Rulebook 2023/24', 'header2': 'Welcome'})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a graph from the chunks\n",
    "\n",
    "You now have chunks prepared for creating a knowledge graph.\n",
    "\n",
    "The graph will have 1 node per chunk, containing the chunk text and metadata as properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge chunk query\n",
    "\n",
    "You will use a Cypher query to merge the chunks into the graph.\n",
    "\n",
    "This query accepts a query parameter called `chunkParam` which is expected\n",
    "to have the data record containing the chunk and metadata.\n",
    "\n",
    "The `MERGE` query will first match an existing node with the same `chunkId` property.\n",
    "\n",
    "If no such node exists, it will create a new node and the `ON CREATE` clause will set the properties using values from the `chunkParam` query parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(c:Chunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        c.source = $chunkParam.source, \n",
    "        c.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        c.path = $chunkParam.path,\n",
    "        c.text = $chunkParam.text,\n",
    "        c.documentUri = $chunkParam.documentUri,\n",
    "        c += $chunkParam.metadata\n",
    "RETURN c\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create nodes for all chunks.\n",
    "# This will use the `merge_chunk_node_query` to create a `:Chunk` node for each chunk.\n",
    "def create_chunk_id(metadata, idx) -> str:\n",
    "    id = metadata[\"header1\"]\n",
    "    if 'header2' in metadata:\n",
    "        id = id + '|' + metadata[\"header2\"]\n",
    "    if 'header3' in metadata:\n",
    "        id = id + '|' + metadata[\"header3\"]\n",
    "    if 'header4' in metadata:\n",
    "        id = id + '|' + metadata[\"header4\"]\n",
    "    id = id + '|' + str(idx)    \n",
    "    return hashlib.sha1(id.encode()).hexdigest()\n",
    "\n",
    "def create_path(metadata) -> str: \n",
    "    path = metadata[\"header1\"]\n",
    "#    if 'header2' in metadata:\n",
    "#        path = path + '/' + metadata[\"header2\"]\n",
    "#    if 'header3' in metadata:\n",
    "#        path = path + '/' + metadata[\"header3\"]\n",
    "#    if 'header4' in metadata:\n",
    "#        path = path + '/' + metadata[\"header4\"]\n",
    "    return path.replace(' ', '_').replace('.', '_').lower()\n",
    "\n",
    "def create_nodes_for_all_chunks(documentUri, chunks):\n",
    "    node_count = 0\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_id = create_chunk_id(chunk.metadata, i)\n",
    "        path = create_path(chunk.metadata)\n",
    "        gdb.execute_query(merge_chunk_node_query, \n",
    "                chunkParam = { \"chunkId\": chunk_id, \"source\":\"\", \"chunkSeqId\":i, \"text\": chunk.page_content, \"metadata\": chunk.metadata, \"path\": path, \"documentUri\": documentUri }\n",
    "        )\n",
    "        node_count += 1\n",
    "    print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare unique constraint\n",
    "\n",
    "Before calling the helper function to create a knowledge graph,\n",
    "we will take one extra step to make sure we don't duplicate data.\n",
    "\n",
    "The uniqueness constraint is also index. It's job is to ensure that\n",
    "a particular property is unique for all nodes that share a common label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record id=10 name='unique_chunk' type='UNIQUENESS' entityType='NODE' labelsOrTypes=['Chunk'] properties=['chunkId'] ownedIndex='unique_chunk' propertyType=None>]\n"
     ]
    }
   ],
   "source": [
    "# Create a uniqueness constraint on the chunkId property of Chunk nodes \n",
    "gdb.execute_query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "\"\"\")\n",
    "\n",
    "created_indexes = gdb.execute_query('SHOW CONSTRAINTS').records\n",
    "print(created_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create index\n",
    "\n",
    "To speed up lookup on the \"path\" property, we create an index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record id=11 name='index_2bc8b8e7' state='ONLINE' populationPercent=100.0 type='RANGE' entityType='NODE' labelsOrTypes=['Chunk'] properties=['path'] indexProvider='range-1.0' owningConstraint=None lastRead=None readCount=None>, <Record id=6 name='sections_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Section'] properties=['summaryEmbedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 17, 46, 42, 478000000, tzinfo=<UTC>) readCount=1>, <Record id=7 name='unique_chunk' state='ONLINE' populationPercent=100.0 type='RANGE' entityType='NODE' labelsOrTypes=['Chunk'] properties=['chunkId'] indexProvider='range-1.0' owningConstraint='unique_chunk' lastRead=None readCount=None>]\n"
     ]
    }
   ],
   "source": [
    "# Create a uniqueness constraint on the chunkId property of Chunk nodes \n",
    "gdb.execute_query(\"\"\"\n",
    "CREATE INDEX FOR (c:Chunk) ON (c.path)\n",
    "\"\"\")\n",
    "\n",
    "created_indexes = gdb.execute_query('SHOW INDEXES').records\n",
    "print(created_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all chunks\n",
    "\n",
    "Perform the node creation for all files in an import directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 271 nodes\n",
      "CPU times: user 182 ms, sys: 32.1 ms, total: 214 ms\n",
      "Wall time: 1.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "create_nodes_for_all_chunks(documents[0].metadata[\"source\"], chunks)\n",
    "\n",
    "# Check the number of nodes in the graph\n",
    "gdb.execute_query(\"MATCH (c:Chunk) RETURN count(c) as chunkCount\").records[0].get('chunkCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Record uniqueHeader4Count=130>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique company CUSIPs (company IDs) in the graph\n",
    "# Expect this to match the `uniqueCompanyCount` from the previous cell\n",
    "gdb.execute_query(\"MATCH (c:Chunk) RETURN count(distinct(c.header4)) as uniqueHeader4Count\").records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance - vector embeddings for the text of each chunk  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "You will use the `embeddings_api` defined in `shared.ipynb` to get the vector embeddings \n",
    "for the text of each chunk. This api will use an LLM to calculate an embedding for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple example of how to use the embeddings API\n",
    "text_embedding = embeddings_api.embed_query(\"embed this text using an LLM\")\n",
    "\n",
    "print(text_embedding)\n",
    "\n",
    "# all embeddings will have the same size, which is the dimensions of the vector\n",
    "vector_dimensions = len(text_embedding) \n",
    "\n",
    "print(f\"Text embeddings will have {vector_dimensions} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a vector index\n",
    "\n",
    "Now that you have a graph populated with `Chunk` nodes, \n",
    "you can add vector embeddings.\n",
    "\n",
    "First, prepare a vector index to store the embeddings.\n",
    "\n",
    "The index will be called `chunks_vector` and will store\n",
    "embeddings for nodes labeled as `Chunk` in a property\n",
    "called `emedding`.\n",
    "\n",
    "The embeddings index will match the dimensions of the \n",
    "embeddings returned by the `embeddings_api` and will use \n",
    "the cosine similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record id=12 name='chunks_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Chunk'] properties=['embedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=None readCount=None>,\n",
       " <Record id=6 name='sections_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Section'] properties=['summaryEmbedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=neo4j.time.DateTime(2024, 6, 2, 17, 46, 42, 478000000, tzinfo=<UTC>) readCount=1>]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector index called \"chunks_vector\" the `embedding`` property of nodes labeled `Chunk`. \n",
    "# neo4j_create_vector_index(kg, VECTOR_INDEX_NAME, 'Chunk', 'embedding')\n",
    "gdb.execute_query(\"\"\"\n",
    "         CREATE VECTOR INDEX `chunks_vector` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.embedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: $vectorDimensionsParam,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\",\n",
    "  vectorDimensionsParam = vector_dimensions\n",
    ")\n",
    "\n",
    "# Check the vector indexes in the graph\n",
    "gdb.execute_query('SHOW VECTOR INDEXES').records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record id=12 name='chunks_vector' state='ONLINE' populationPercent=100.0 type='VECTOR' entityType='NODE' labelsOrTypes=['Chunk'] properties=['embedding'] indexProvider='vector-2.0' owningConstraint=None lastRead=None readCount=0>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Langchain to create the vector index (alternative to the previous cell)\n",
    "from langchain.vectorstores import Neo4jVector\n",
    "Neo4jVector.from_existing_graph(\n",
    "    embedding=embeddings_api,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE,\n",
    "    index_name='chunks_vector',\n",
    "    node_label=\"Chunk\",\n",
    "    text_node_properties=['text'],\n",
    "    embedding_node_property='embedding',\n",
    ")\n",
    "\n",
    "# Check the vector indexes in the graph\n",
    "gdb.execute_query('SHOW VECTOR INDEXES').records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text embeddings\n",
    "\n",
    "Creating the text embeddings will be a two step process. \n",
    "\n",
    "First, collect all chunk text and chunk ids from the graph.\n",
    "Yes these are the same chunk ids that were used to create the graph\n",
    "and you could save time by doing this all at once. We're doing\n",
    "this incrementally to show the process, not optimized for speed.\n",
    "\n",
    "Next, use the `embeddings_api` to get the embeddings for the text\n",
    "and write those values back into the graph. \n",
    "\n",
    "This will take some time to run as we're doing it one chunk at a time,\n",
    "calling out to the `embeddings_api` for each then writing all those\n",
    "results back into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding all chunks that need embedding...\n",
      "Generating vector embeddings, then writing into each chunk...\n",
      "CPU times: user 1.82 s, sys: 209 ms, total: 2.03 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def text_for_embedding(text, header2, header3, header4) -> str:\n",
    "    text_for_embed = text;\n",
    "    if header4 is not None:\n",
    "        text_for_embed = header4 + '>>' + text_for_embed\n",
    "    return text_for_embed;\n",
    "\n",
    "# Create vector embeddings for all the Chunk text, in batches.\n",
    "# Use this for larger number of chunks so that the query\n",
    "# can be re-run without losing all progress\n",
    "print(\"Finding all chunks that need embedding...\")\n",
    "all_chunks_for_embed = gdb.execute_query(\"\"\"\n",
    "  MATCH (chunk:Chunk) WHERE chunk.embedding IS NULL\n",
    "  RETURN chunk.text AS text, chunk.header2 as header2, chunk.header3 as header3, chunk.header4 as header4, chunk.chunkId AS chunkId\n",
    "  \"\"\").records\n",
    "\n",
    "print(\"Generating vector embeddings, then writing into each chunk...\")\n",
    "for chunk in all_chunks_for_embed:\n",
    "  text = text_for_embedding(chunk['text'], chunk['header2'], chunk['header3'], chunk['header4'])\n",
    "  #print (text)\n",
    "  embedding = embeddings_api.embed_query(text)\n",
    "  gdb.execute_query(\"\"\"\n",
    "    MATCH (chunk:Chunk {chunkId: $chunkIdParam})\n",
    "    CALL db.create.setNodeVectorProperty(chunk, \"embedding\", $embeddingParam)    \n",
    "    \"\"\", \n",
    "    chunkIdParam=chunk['chunkId'], embeddingParam=embedding\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand - connect the chunks into linked lists\n",
    "\n",
    "You can now create relationships between all\n",
    "nodes in that list of chunks,\n",
    "effectively creating a linked list from the\n",
    "first chunk to the last.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 ms, sys: 4.96 ms, total: 7.63 ms\n",
      "Wall time: 37.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Collect all the form IDs and form 10k item names\n",
    "distinct_path_result = gdb.execute_query(\"\"\"\n",
    "MATCH (c:Chunk) RETURN DISTINCT c.path as path\n",
    "\"\"\").records\n",
    "\n",
    "distinct_path_list = list(map(lambda x: x['path'], distinct_path_result))\n",
    "\n",
    "# Connect *all* section chunks into a linked list..\n",
    "cypher = \"\"\"\n",
    "  MATCH (from_same_path:Chunk) // match all chunks\n",
    "  WHERE from_same_path.path = $path // where the chunks are from the same path\n",
    "  WITH from_same_path // with those collections of chunks\n",
    "    ORDER BY from_same_path.chunkSeqId ASC // order the chunks by their sequence ID\n",
    "  WITH collect(from_same_path) as same_path_chunk_list // collect the chunks into a list\n",
    "    CALL apoc.nodes.link(same_path_chunk_list, \"NEXT\", {avoidDuplicates: true}) // then create a linked list in the graph\n",
    "  RETURN size(same_path_chunk_list)\n",
    "\"\"\"\n",
    "\n",
    "for path in distinct_path_list:\n",
    "    gdb.execute_query(cypher, \n",
    "             path=path\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example questions - vector similarity search with Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Neo4j vector search helper\n",
    "\n",
    "The `shared.ipynb` notebook has a helper function to perform a vector similarity search\n",
    "using the Neo4j Knowledge Graph.\n",
    "\n",
    "It will perform vector similarity search using the `chunks_vector` vector index.\n",
    "\n",
    "Try it out by searching for information about one of the companies in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vector index: chunks_vector\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Record score=0.817984938621521 text='The official size of the Rink shall be 60 m long and 26 m to 30 m wide. The corners shall be rounded in the arc of a circle with a radius of 7.0 m to 8.50 m. Any deviations from these dimensions for any IIHF competition require IIHF approval.'>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = neo4j_vector_search(\n",
    "    'what is the size of the rink?', VECTOR_INDEX_NAME\n",
    ")\n",
    "search_results[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question Answering chat with Langchain \n",
    "\n",
    "Notice that we only performed vector search. So what we're getting\n",
    "back is the raw chunk text.\n",
    "\n",
    "If we want to create a chatbot that provides actual answers to\n",
    "a question, we can build a RAG system using Langchain.\n",
    "\n",
    "The basic RAG flow goes through these steps:\n",
    "\n",
    "1. accept a question from the user\n",
    "2. perform a database query to find relevant text that may provide an answer\n",
    "3. package the original question plus the relevant text into a prompt\n",
    "4. pass the entire prompt to an LLM to produce an answer\n",
    "5. finally, return the LLM's answer to the user\n",
    "\n",
    "Langchain is a great framework for creating a complete RAG workflow.\n",
    "\n",
    "It has excellent integration with Neo4j. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In professional and amateur ice hockey, the standard size of an NHL-sized ice hockey rink is:\\n\\n* Length: 200 feet (61 meters)\\n* Width: 85 feet (26 meters)\\n\\nThis is the same size used in the National Hockey League (NHL) and many other international competitions. The dimensions are specified by the International Ice Hockey Federation (IIHF).\\n\\nIt\\'s worth noting that there are smaller rinks, often referred to as \"junior\" or \"youth\" rinks, which are typically 180 feet (55 meters) long and 80 feet (24 meters) wide. These smaller rinks are used for younger age groups or recreational play.\\n\\nIn some countries, like Europe, the rink size may be slightly different, but the NHL-sized dimensions are widely adopted as the standard.'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the chat api directly\n",
    "result = chat_api.invoke(\"what is the size of the icehockey rink\")\n",
    "\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neo4j Vector Store\n",
    "\n",
    "The easiest way to start using Neo4j with Langchain\n",
    "is with the `Neo4jVector` interface.\n",
    "\n",
    "This makes Neo4j look like a vector store using\n",
    "the vector index you created earlier.\n",
    "\n",
    "Under the hood, it will use the Cypher language\n",
    "for performing vector similarity searches.\n",
    "\n",
    "The configuration specifies a few important things:\n",
    "- use the defined `embeddings_api` for embeddings\n",
    "- how to connect to the Neo4j database\n",
    "- the name of the vector index to use\n",
    "- the label of the nodes to search\n",
    "- the property name of the text on those nodes\n",
    "- and, the property name of the embeddings on those nodes\n",
    "\n",
    "That vector store then gets converted into a retriever\n",
    "and finally added to a Question Answering chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a langchain vector store from the existing Neo4j knowledge graph.\n",
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=embeddings_api,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    node_label=VECTOR_NODE_LABEL,\n",
    "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt-llama\")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever = neo4j_vector_store.as_retriever()\n",
    "\n",
    "# Create a chatbot Question & Answer chain from the retriever\n",
    "#chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "#    chat_api, chain_type=\"stuff\", retriever=retriever\n",
    "#)\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    chat_api, chain_type=\"stuff\", retriever=retriever, verbose=True, chain_type_kwargs={\"prompt\": prompt, \"verbose\": True}\n",
    ")\n",
    "\n",
    "prettyVectorSearch = prettifyChain(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask some questions\n",
    "\n",
    "Finally, you can use the Langchain chain, which combines the retriever\n",
    "and the vector store into a nice question and answer interface.\n",
    "\n",
    "You can see both the answer and the source that the answer came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: [INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \n",
      "Question: who needs visor or facial protection \n",
      "Context: \n",
      "text: The compilation and the explanations of the signals of the Game Officials are located in the Appendix I.\n",
      "\n",
      "\n",
      "text: There are three (3) permissible types of facial protection which can be attached to the front of a Players’ helmet: a visor protection, a cage protection, or a full-face protection visor.\n",
      "\n",
      "\n",
      "text: Dangerous Equipment includes wearing a visor in a way that may cause injury to an opponent, wearing non-approved equipment, using dangerous or illegal skates or stick, failing to wear equipment under the uniform (except gloves, helmet, and goalkeeper’s pads), and cutting the palm out of one or both gloves.\n",
      "\n",
      "\n",
      "text: A list of the infractions that shall result in a penalty to the Goalkeeper can be found in Table 13. \n",
      "Answer: [/INST]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[/INST]<<SYS>> Players who need visor or facial protection are those wearing a\n",
      "helmet and using one of three permissible types of facial protection: visor,\n",
      "cage, or full-face protection visor. This is to ensure safety on the field.\n",
      "Wearing a visor in a way that may cause injury to an opponent is considered\n",
      "dangerous equipment.\n"
     ]
    }
   ],
   "source": [
    "prettyVectorSearch(\"who needs visor or facial protection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: [INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \n",
      "Question: what is the size of the rink? \n",
      "Context: \n",
      "text: The official size of the Rink shall be 60 m long and 26 m to 30 m wide. The corners shall be rounded in the arc of a circle with a radius of 7.0 m to 8.50 m. Any deviations from these dimensions for any IIHF competition require IIHF approval.\n",
      "\n",
      "\n",
      "text: For more information for Supplementary Discipline in pre-championship games and exhibition games, refer to the IIHF Disciplinary Code.\n",
      "\n",
      "\n",
      "text: Within the Face-off Spot, draw two parallel lines 8 cm from the top and bottom of the spot. The area within the two lines shall be painted red, the remainder shall be painted white. The spots shall be 14.0 m apart and each shall be a uniform distance from the adjacent Boards.  \n",
      "**Face-off Spots and Circles in the End-Zones (Attacking and Defending Zone):**  \n",
      "In both End-zones and on both sides of each goal, red Face-off Spots and circles shall be marked on the ice.  \n",
      "The Face-off Spots shall be 60 cm in diameter. These four (4) spots shall be referred to as the “End-zone Face-off Spots”.\n",
      "\n",
      "\n",
      "text: When play has been stopped, the Player whose penalty has fully expired may return to the ice. During the play, the Penalty Time- keeper shall permit the penalized Players to return to the ice, in the order of expiration of their penalties, but only when the penalized Team is entitled to have more than four (4) Players on the ice. Otherwise, these Players must wait until the first stoppage of play after the expiration of their penalties in order to be released from the Penalty Box. \n",
      "Answer: [/INST]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[/INST]<<SYS>> The size of the rink is 60 m long and 26-30 m wide.\n"
     ]
    }
   ],
   "source": [
    "prettyVectorSearch(\"what is the size of the rink?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector search with graph pattern\n",
    "\n",
    "You can now create a question answering chain.\n",
    "\n",
    "The default Neo4jVector uses a basic cypher query\n",
    "to peform vector similarity search.\n",
    "\n",
    "That query can be extended to do whatever you\n",
    "want in a Cypher.\n",
    "\n",
    "This Cypher query extension will receive two variables: `node` and `score`\n",
    "and it should should return three fields: `text`, `score`, and `metadata`.\n",
    "\n",
    "  - The `text` should be plain text to be passed to the LLM.\n",
    "  - The `score` column should be the similarity score of the text.\n",
    "  - The `metadata` can be any additional information you want to pass, like the source of the text.\n",
    "\n",
    "\n",
    "In this example, we'll use the previous/next chunks to expand the context of the text passed to the LLM.\n",
    "\n",
    "Create two QA chains, one with and one without the chunk window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_query_window = \"\"\"\n",
    "OPTIONAL MATCH window=\n",
    "    (:Chunk)-[:NEXT*0..1]->(node)-[:NEXT*0..1]->(:Chunk)\n",
    "WITH node, score, window as longestWindow \n",
    "  ORDER BY node, length(window) DESC LIMIT 1\n",
    "WITH nodes(longestWindow) as chunkList, node, score\n",
    "  UNWIND chunkList as chunkRows\n",
    "WITH collect(chunkRows.text) as textList, node, score\n",
    "RETURN apoc.text.join(textList, \" \\n \") as text,\n",
    "    score,\n",
    "    node {.source} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "vector_store_window = Neo4jVector.from_existing_index(\n",
    "    embedding=embeddings_api,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=\"neo4j\",\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    text_node_property=VECTOR_SOURCE_PROPERTY,\n",
    "    retrieval_query=retrieval_query_window\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever_window = vector_store_window.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "# Create a chatbot Question & Answer chain from the retriever\n",
    "chain_window = prettifyChain(RetrievalQA.from_chain_type(\n",
    "    chat_api, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever_window,\n",
    "    chain_type_kwargs={\"verbose\": True}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='For more information for Supplementary Discipline in pre-championship games and exhibition games, refer to the IIHF Disciplinary Code.', metadata={'source': ''})]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever_window.invoke(\"What can you tell me about the rink\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "The official size of the Rink shall be 60 m long and 26 m to 30 m wide. The corners shall be rounded in the arc of a circle with a radius of 7.0 m to 8.50 m. Any deviations from these dimensions for any IIHF competition require IIHF approval.\n",
      "Human: What is the size of a rink and what is the height of the boards\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "According to the provided context, the official size of the Rink shall be:  *\n",
      "Length: 60 m * Width: 26 m to 30 m  As for the height of the boards, it's not\n",
      "mentioned in the given context. If you're looking for information on the\n",
      "standard height of hockey boards, I can try to find that out for you!\n"
     ]
    }
   ],
   "source": [
    "chain_window(\"What is the size of a rink and what is the height of the boards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vector index: chunks_vector\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Record text='The official size of the Rink shall be 60 m long and 26 m to 30 m wide. The corners shall be rounded in the arc of a circle with a radius of 7.0 m to 8.50 m. Any deviations from these dimensions for any IIHF competition require IIHF approval.' score=0.817984938621521 metadata={'source': ''}>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_query_window = \"\"\"\n",
    "OPTIONAL MATCH window=\n",
    "    (:Chunk)-[:NEXT*0..1]->(node)-[:NEXT*0..1]->(:Chunk)\n",
    "WITH node, score, window as longestWindow \n",
    "  ORDER BY node, length(window) DESC LIMIT 1\n",
    "WITH nodes(longestWindow) as chunkList, node, score\n",
    "  UNWIND chunkList as chunkRows\n",
    "WITH collect(chunkRows.text) as textList, node, score\n",
    "RETURN apoc.text.join(textList, \" \\n \") as text,\n",
    "    score,\n",
    "    node {.source} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "def neo4j_vector_search_2(question, retrieval_query):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  vector_search_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, $question_embedding) \n",
    "        YIELD node, score\n",
    "  \"\"\" + retrieval_query\n",
    "  similar = []\n",
    "\n",
    "  print (\"Using vector index: \" + str(VECTOR_INDEX_NAME))\n",
    "    \n",
    "  question_embedding = embeddings_api.embed_query(question)\n",
    "  return gdb.execute_query(vector_search_query,\n",
    "                      question=question, \n",
    "                      question_embedding=question_embedding, \n",
    "                      index_name=VECTOR_INDEX_NAME, \n",
    "                      top_k=10\n",
    "                    ).records\n",
    "\n",
    "search_results = neo4j_vector_search_2(\n",
    "    'what is the size of the rink?', retrieval_query_window\n",
    ")\n",
    "search_results[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
